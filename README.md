# Стандарт надежности архитектуры ИТ-инфраструктуры

## Введение

Высокая надежность информационных систем — ключевой фактор успешной цифровой трансформации бизнеса. Данный стандарт описывает архитектурные подходы к обеспечению надежности ИТ-инфраструктуры с учетом современных требований, включая курс на импортозамещение технологий (переход на отечественные аппаратные и программные решения). Цель — предоставить универсальные схемы и методы для достижения требуемых уровней доступности (SLA) систем вплоть до 99,99% (не более ~52 минут простоя в год).

Документ опирается на лучшие мировые практики: TOGAF, ISO/IEC 27001, ITIL. Применяются принципы корпоративной архитектуры, управления рисками, резервирования и отказоустойчивости, а также процессы управления доступностью и непрерывностью сервисов.

---

## Классификация критичности и цели по доступности

В архитектуре выделяются 4 уровня надежности сервисов:

1. **Низкая критичность (99% SLA)** — допустимы простои до нескольких дней в году (тестовые, вспомогательные системы).
2. **Средняя критичность (99.9% SLA)** — допустимы простои до 8 часов в году (важные, но не критичные бизнес-приложения).
3. **Высокая критичность (99.95–99.99% SLA)** — простои до 52 минут в год, требуется отказоустойчивая архитектура (электронная коммерция, платежные системы).
4. **Критически важные (99.99%+ SLA)** — практически непрерывная работа, RPO/RTO близки к нулю (банковские системы, системы управления движением).

Для каждого уровня определяются требования к резервированию, восстановлению, географическому дублированию, мониторингу и тестированию аварийного восстановления. Системы проектируются с учетом перспективного роста нагрузки и данных, с резервом по масштабированию.

---

## Архитектурные компоненты и технологии

- **Балансировка нагрузки:** отказоустойчивые балансировщики (F5 BIG-IP, HAProxy, Nginx), глобальный DNS-роутинг, Ingress-контроллеры Kubernetes.
- **Оркестрация и среда выполнения:** контейнеризация и Kubernetes (минимум 3 master-ноды, отдельные кластеры на площадках, автоматический перезапуск и масштабирование).
- **Слой приложений:** stateless-микросервисы, хранение состояния вне узлов (Redis), кластеризация монолитов, отказоустойчивые планировщики задач.
- **Интеграция и шина данных:** Apache Kafka (кластер, репликация, CDC через Debezium), RabbitMQ/IBM MQ (кластеризация, подтверждения, персистентность).
- **Хранилища данных:** PostgreSQL (Patroni, мастер-реплика, синхронная репликация), Redis (Sentinel, кластер), Tarantool, Elasticsearch (реплики, кворум).

Все компоненты объединяются в многоуровневую архитектуру с устранением единичных точек отказа.

---

## Геораспределение и концепция 2.5 ЦОД

- **2.5 ЦОД:** два основных дата-центра + третий арбитр для кворума (например, ZooKeeper, etcd). Синхронная репликация между основными площадками, witness-узел для избежания split-brain.
- **Ограничение области отказа:** кластеры не растягиваются между удалёнными ЦОД без необходимости, каждый ЦОД — независимый стек.
- **Актив-актив и актив-пассив:** для критичных систем — актив-актив (оба ЦОДа обслуживают трафик), для менее критичных — актив-пассив (резервная площадка).

---

## Резервирование, отказоустойчивость и восстановление

- **Резервирование:** дублирование серверов, сетей, питания, запуск сервисов на разных узлах, репликация БД и очередей.
- **Автоматический failover:** мониторинг, автоматическое переключение, защита от ложных срабатываний.
- **Паттерны устойчивого дизайна:** bulkhead, circuit breaker, graceful degradation, retry with backoff, идемпотентность, буферизация.
- **Масштабирование:** горизонтальное (HPA в Kubernetes), вертикальное, шардирование БД, распределённые файловые системы.
- **Автоматическое восстановление:** инфраструктура как код (Ansible, Terraform), регулярные учения по DR, Chaos Engineering.

---

## Непрерывность работы при обновлениях

- **Blue-Green Deployment:** параллельные инсталляции, быстрое переключение.
- **Canary Releases:** постепенное включение новой версии.
- **Rolling Update:** поочередное обновление экземпляров.
- **Автоматический откат:** rollback при ошибках.
- **Непрерывное тестирование:** автоматические тесты, performance/failure-injection.
- **Мониторинг релизов:** метрики, алерты, A/B-тесты, фичефлаги.

---

## Обеспечение доставки и консистентности данных

- **Синхронные операции:** транзакции, синхронная репликация для критичных данных.
- **Асинхронные сценарии:** Kafka, CDC, eventual consistency, идемпотентность событий, reconciliation.
- **CAP-принцип:** для критичных систем — при потере связи лучше остановить часть функций, чем допустить расхождение данных.

---

## Мониторинг, анализ и улучшение надежности

- **Метрики и алертинг:** Prometheus, Grafana, Zabbix, отечественные аналоги.
- **Логирование и трассировка:** ELK-стек, Jaeger, Zipkin.
- **Incident Management:** регламент, анализ инцидентов, post-mortem.
- **Capacity Management:** планирование ресурсов, масштабирование.
- **Тестирование восстановления:** регулярные учения, проверка бэкапов.

---

## Безопасная разработка (DevSecOps)

- **SAST:** статический анализ кода (SonarQube, Solar appScreener).
- **SCA:** анализ зависимостей (CVE, лицензии).
- **DAST:** динамическое тестирование (OWASP ZAP).
- **BCA:** анализ контейнеров и артефактов.
- **Безопасное конфигурирование:** IaC SAST (Checkov, KICS).
- **Интеграция в CI/CD:** автоматическая блокировка релиза при обнаружении критичных уязвимостей.

---

## Заключение

Стандарт надежности архитектуры ИТ-инфраструктуры объединяет:
- Дублирование компонентов и устранение единой точки отказа.
- Геораспределение и готовность к катастрофическим сбоям.
- Автоматизацию обнаружения и восстановления.
- Продуманную стратегию релизов без downtime.
- Обеспечение целостности данных.
- Постоянный мониторинг и улучшение процессов.
- Интеграцию безопасности в разработку.

Следуя этим рекомендациям, организация может построить устойчивую инфраструктуру, способную выдерживать сбои оборудования, ошибки ПО и внешние угрозы без существенного воздействия на пользователей.
